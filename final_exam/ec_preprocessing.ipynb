{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data access\n",
    "import io\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# data handling\n",
    "import json\n",
    "\n",
    "# internet\n",
    "import requests\n",
    "\n",
    "# data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "#import scikit-learn as sk\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# system packages\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 5]\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my own libs\n",
    "from libs.gov_eneff import rt\n",
    "\n",
    "rt.init('config/config.json')\n",
    "logger = rt.logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gov_eneff import db\n",
    "reload(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "db.load(source='pg')\n",
    "\n",
    "# 2019-04-28 21:24:41 - DEBUG - Have fetched 44708 records of declarations of buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld = db.df_bld.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declrs_f_seq = pd.Index(pd.read_csv('data/declrs_fields_sequence.txt', header=None)[0])\n",
    "declr_buildings_f_seq = pd.Index(pd.read_csv('data/declr_buildings_fields_sequence.txt', header=None)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr = db.df_declr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declrs_f_seq_complemented = declrs_f_seq.append(df_declr.columns[~df_declr.columns.isin(declrs_f_seq)])\n",
    "\n",
    "print(df_declr.shape)\n",
    "dft = df_declr\\\n",
    "    .reindex(columns=declrs_f_seq_complemented)\\\n",
    "    .copy()\n",
    "print(dft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2 = dft.columns.to_frame().merge(db.md_cols.query('table_name == \"declrs\"')[['column_name', 'column_comment']].set_index('column_name'),\n",
    "                      left_index=True, right_index=True, how='left')\\\n",
    "    .drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2.to_excel('data/local_db/declr_attrs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declr_buildings_f_seq_complemented = declr_buildings_f_seq.append(df_bld.columns[~df_bld.columns.isin(declr_buildings_f_seq)])\n",
    "\n",
    "print(df_bld.shape)\n",
    "print(len(declr_buildings_f_seq_complemented))\n",
    "\n",
    "dft = df_bld\\\n",
    "    .reindex(columns=declr_buildings_f_seq_complemented)\\\n",
    "    .copy()\n",
    "print(dft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2 = dft.columns.to_frame().merge(db.md_cols.query('table_name == \"declr_buildings\"')[['column_name', 'column_comment']].set_index('column_name'),\n",
    "                      left_index=True, right_index=True, how='left')\\\n",
    "    .drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2.to_excel('data/local_db/bld_attrs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Features to Buidlings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buildings Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df_bld_geo = pd.read_parquet('data/df_bld_geo.parquet')\n",
    "\n",
    "# converting 'geocoder_response' from string back to dictionary\n",
    "df_bld_geo['geocoder_response']= df_bld_geo['geocoder_response'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j = df_bld_geo['geocoder_response'].iloc[0]\n",
    "#print(json.dumps(j, ensure_ascii=False, indent=4))\n",
    "\n",
    "#print(j['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['Point']['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(j['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['metaDataProperty']['GeocoderMetaData']['text'])\n",
    "# print(j['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['metaDataProperty']['GeocoderMetaData']['kind'])\n",
    "# print(j['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['metaDataProperty']['GeocoderMetaData']['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ya_geo_data(x):\n",
    "    \n",
    "    res = {'ya_geo_text': None, 'ya_geo_kind': None, 'ya_geo_area2': None, 'ya_geo_precision': None, 'ya_geo_pos': None}\n",
    "    \n",
    "    try:\n",
    "        geo_obj = x['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']\n",
    "        res['ya_geo_text']      = geo_obj['metaDataProperty']['GeocoderMetaData']['text']\n",
    "        res['ya_geo_kind']      = geo_obj['metaDataProperty']['GeocoderMetaData']['kind']\n",
    "        try:\n",
    "            res['ya_geo_area2']     = geo_obj['metaDataProperty']['GeocoderMetaData']['AddressDetails']['Country']['AdministrativeArea']['SubAdministrativeArea']['SubAdministrativeAreaName']\n",
    "        except KeyError:\n",
    "            res['ya_geo_area2'] = None\n",
    "        res['ya_geo_precision'] = geo_obj['metaDataProperty']['GeocoderMetaData']['precision']        \n",
    "        res['ya_geo_pos']       = geo_obj['Point']['pos']\n",
    "    except IndexError:\n",
    "        geo_data = None\n",
    "        \n",
    "    return(res)\n",
    "\n",
    "# this is very ineffective, need to improve it later\n",
    "for col_name in ('ya_geo_text', 'ya_geo_kind', 'ya_geo_area2', 'ya_geo_precision', 'ya_geo_pos'):\n",
    "    df_bld_geo[col_name] = df_bld_geo['geocoder_response'].apply(lambda x: get_ya_geo_data(x)[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld = df_bld.merge(df_bld_geo[['actual_address', 'ya_geo_text', 'ya_geo_kind', 'ya_geo_area2', 'ya_geo_precision', 'ya_geo_pos']].set_index('actual_address'),\n",
    "                              left_on='actual_address', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DaData Info (OKVED etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dadata_orgs2 = pd.read_excel('data/orgs_dadata.xlsx', dtype={'inn': 'object'}).set_index('inn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld = df_bld.merge(df_dadata_orgs2[['okved', 'okved_type', \n",
    "                                             'area_type', 'area', \n",
    "                                             'city_type', 'city',\n",
    "                                             'geo_lat', 'geo_lon', 'geo_qc']]\\\n",
    "                           .rename(columns={'okved': 'dd_okved', \n",
    "                                            'okved_type': 'dd_okved_type', \n",
    "                                            'area': 'dd_area', \n",
    "                                            'area_type': 'dd_area_type',\n",
    "                                            'city': 'dd_city', \n",
    "                                            'city_type': 'dd_city_type',\n",
    "                                            'geo_lat': 'dd_geo_lat', \n",
    "                                            'geo_lon': 'dd_geo_lon', \n",
    "                                            'geo_qc': 'dd_geo_qc'}), \n",
    "                     left_on='inn',\n",
    "                     right_index=True,\n",
    "                     how='left').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['main_okved_code_l1'] = df_bld['main_okved_code'].str.extract('([0-9]+?)\\.').fillna('')\n",
    "df_bld['main_okved_code_l2'] = df_bld['main_okved_code'].str.extract('([0-9]+?\\.[0-9]+?)\\.').fillna('')\n",
    "\n",
    "df_bld['dd_okved_code_l1']   = df_bld['dd_okved'].str.extract('([0-9]+?)\\.').fillna('')\n",
    "df_bld['dd_okved_code_l2']   = df_bld['dd_okved'].str.extract('([0-9]+?\\.[0-9]+?)\\.').fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['dd_area_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['dd_city_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['dd_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['ya_geo_precision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['ya_geo_pos'].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_climate_zone(x, source):\n",
    "    \"\"\"\n",
    "    1 - 'North'\n",
    "    2 - 'Middle'\n",
    "    3 = 'South'\n",
    "    \"\"\"\n",
    "    \n",
    "    cz = None\n",
    "    \n",
    "    if source=='yandex':\n",
    "    \n",
    "        if pd.isna(x['ya_geo_pos']):\n",
    "            cz = 2\n",
    "        else:\n",
    "            #print(x['ya_geo_pos'])\n",
    "            lattitude = x['ya_geo_pos'].split(' ')[1]\n",
    "            #print(lattitude)\n",
    "            lattitude = float(lattitude)\n",
    "            if lattitude > 56:\n",
    "                cz = 1\n",
    "            elif lattitude < 55:\n",
    "                cz = 3\n",
    "            else:\n",
    "                cz = 2\n",
    "\n",
    "    elif source == 'dadata':\n",
    "        \n",
    "        if pd.isna(x['dd_geo_lat']):\n",
    "            cz = 2\n",
    "        else:\n",
    "            #print(x['ya_geo_pos'])\n",
    "            lattitude = x['dd_geo_lat']\n",
    "            #print(lattitude)\n",
    "            lattitude = float(lattitude)\n",
    "            if lattitude > 56:\n",
    "                cz = 1\n",
    "            elif lattitude < 55:\n",
    "                cz = 3\n",
    "            else:\n",
    "                cz = 2\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        raise ValueError\n",
    "                \n",
    "    return(cz)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['ya_climate_zone'] = df_bld.apply(lambda x: get_climate_zone(x, source='yandex'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['dd_climate_zone'] = df_bld.apply(lambda x: get_climate_zone(x, source='dadata'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_bld['ya_climate_zone'] == df_bld['dd_climate_zone']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.df_bld = df_bld.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save(dest='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ### Appendix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Sources - Meant to Be Run Once / Skip if Uncertain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo (Yandex Geocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gov_eneff.utils import Geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoder = Geocoder()\n",
    "\n",
    "# removing duplicates\n",
    "df_bld_geo = db.df_bld[['actual_address']].drop_duplicates().copy()\n",
    "df_bld_geo['geocoder_response'] = np.nan\n",
    "\n",
    "df_bld_geo.iloc[:, 1] = df_bld_geo['actual_address'].iloc[:].apply(lambda x: geocoder.by_address(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = df_bld_geo['geocoder_response'].iloc[0]\n",
    "\n",
    "# json.dumps(j, ensure_ascii=False, sort_keys=True)\n",
    "\n",
    "# print(j['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['metaDataProperty']['GeocoderMetaData'] \\\n",
    "#           ['Address']['Components'])\n",
    "\n",
    "# print(j['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['Point']['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld_geo.astype({'actual_address': str, 'geocoder_response': str}, skipna=False).to_parquet('data/df_bld_geo.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Org Info (Inc. OKVED) from DaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_org_info(inn):\n",
    "    \n",
    "    # https://dadata.ru/api/find-party/\n",
    "    \n",
    "    # До 10 июля 2016 года использовался старый классификатор ОКВЭД ОК 029-2001 (КДЕС Ред.1), но с 11 июля 2016 года ФНС перешла на новую редакцию классификатора ОКВЭД-2 (версия ОК 029-2014 (КДЕС Ред. 2)).\n",
    "    # Замену кодов старого классификатора на коды нового классификатора для юридических и физических лиц, зарегистрированных до 11 июля 2016 года, произвели автоматически. С 11 июля 2016 года использование старых кодов строго запрещено. В случае пренебрежения данного требования налоговая инспекция выносит отказы в регистрации. Чтобы не ошибиться в правильности выбора и облегчить поиск новых кодов приводим сравнительную таблицу старых кодов к новым.\n",
    "    \n",
    "    auth_token = rt.config['dadata']['auth_token']\n",
    "    \n",
    "    headers = {'Content-Type': 'application/json',\n",
    "               'Accept': 'application/json', \n",
    "               'Authorization': f'Token {auth_token}'}\n",
    "    \n",
    "    r = requests.get('https://suggestions.dadata.ru/suggestions/api/4_1/rs/findById/party', \n",
    "                     params={'query': inn}, headers=headers)\n",
    "    #time.sleep(.2)\n",
    "    \n",
    "    return(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_org_info('5029144163')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = get_org_info('5030020966')\n",
    "# print(json.dumps(r, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dadata_orgs = db.df_declr.query('inn == inn')['inn'].drop_duplicates().to_frame()\n",
    "df_dadata_orgs['org_data'] = df_dadata_orgs.apply(lambda x: get_org_info(x['inn']), axis=1)\n",
    "df_dadata_orgs = df_dadata_orgs.set_index('inn', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dadata_orgs.astype({'org_data': str}, skipna=False).to_parquet('data/dadata_orgs_by_inn.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(df_dadata_orgs.loc['5007051116'].iloc[0], ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = df_dadata_orgs.loc['5034082850'].iloc[0]\n",
    "#print(r['suggestions'][0]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for key, r in df_dadata_orgs['org_data'].iteritems():\n",
    "    \n",
    "    if r is None:\n",
    "        continue\n",
    "        \n",
    "    if len(r['suggestions']) == 0:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        records.append([\n",
    "            key,\n",
    "            # r['suggestions'][0]['data']['opf']['full'],\n",
    "            r['suggestions'][0]['data']['name']['full'],\n",
    "            r['suggestions'][0]['data']['name']['short'],\n",
    "            r['suggestions'][0]['data']['state']['status'],\n",
    "            r['suggestions'][0]['data']['state']['registration_date'],\n",
    "            r['suggestions'][0]['data']['state']['liquidation_date'],\n",
    "            r['suggestions'][0]['data']['state']['actuality_date'],\n",
    "            r['suggestions'][0]['data']['okved'],\n",
    "            r['suggestions'][0]['data']['okved_type'],\n",
    "            r['suggestions'][0]['data']['address']['value'],\n",
    "            r['suggestions'][0]['data']['address']['data']['region_with_type'],\n",
    "            r['suggestions'][0]['data']['address']['data']['area'],\n",
    "            r['suggestions'][0]['data']['address']['data']['area_type'],\n",
    "            r['suggestions'][0]['data']['address']['data']['city'],\n",
    "            r['suggestions'][0]['data']['address']['data']['city_type'],\n",
    "            r['suggestions'][0]['data']['address']['data']['timezone'],\n",
    "            r['suggestions'][0]['data']['address']['data']['geo_lat'],\n",
    "            r['suggestions'][0]['data']['address']['data']['geo_lon'],\n",
    "            r['suggestions'][0]['data']['address']['data']['qc_geo'],\n",
    "            r['suggestions'][0]['data']['qc']])\n",
    "    except:\n",
    "        print(key)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.DataFrame(records, columns=['inn', 'full_name', 'short_name', 'status', \n",
    "                               'registration_date', 'liquidation_date', 'actuality_date',\n",
    "                               'okved', 'okved_type',\n",
    "                               'address', 'region', 'area', 'area_type', 'city', 'city_type',\n",
    "                               'timezone', 'geo_lat', 'geo_lon', 'geo_qc', 'data_qc']).set_index('inn')\n",
    "\n",
    "dft['registration_date'] = pd.to_datetime(dft['registration_date'], unit='ms')\n",
    "dft['liquidation_date']  = pd.to_datetime(dft['liquidation_date'], unit='ms')\n",
    "dft['actuality_date']    = pd.to_datetime(dft['actuality_date'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dadata_orgs2 = df_dadata_orgs.merge(dft, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dadata_orgs2.to_excel('data/orgs_dadata.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dadata_orgs2['okved'].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- http://economy.gov.ru/minec/activity/sections/classificators/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.516px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
