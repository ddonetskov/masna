{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data access\n",
    "import io\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# data handling\n",
    "import json\n",
    "\n",
    "# internet\n",
    "import requests\n",
    "\n",
    "# data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "#import scikit-learn as sk\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# system packages\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 5]\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my own libs\n",
    "from libs.gov_eneff import rt\n",
    "\n",
    "rt.init('config/config.json')\n",
    "logger = rt.logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG='en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gov_eneff import db\n",
    "reload(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.DB()\n",
    "db.load(source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_cols     = db.md_cols.copy()\n",
    "\n",
    "df_org      = db.df_org.copy()\n",
    "df_declr    = db.df_declr.copy()\n",
    "df_bld      = db.df_bld.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declrs_f_seq = pd.Index(pd.read_csv('data/declrs_fields_sequence.txt', header=None)[0])\n",
    "print(len(declrs_f_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declr_buildings_f_seq = pd.Index(pd.read_csv('data/declr_buildings_fields_sequence.txt', header=None)[0])\n",
    "(print(len(declr_buildings_f_seq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data - Org Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking data from the database instead of db.df_declr as the former may not contain all properties\n",
    "\n",
    "stmt = sa.sql.text('''\n",
    "select *\n",
    "  from declrs\n",
    " where fake=0\n",
    "''')\n",
    "df_declr_tmp= pd.read_sql_query(stmt, con=rt.db_engine['energy'])\n",
    "print(df_declr_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr_misses = df_declr_tmp.query('year < 2019')\\\n",
    "    .melt(id_vars='year').groupby(['year', 'variable'])\\\n",
    "    .apply(lambda x: round(100*x['value'].isnull().sum()/len(x['value']), 2))\\\n",
    "    .rename('pct')\\\n",
    "    .to_frame().reset_index()\\\n",
    "    .pivot(index='variable', columns='year')\n",
    "\n",
    "# the more value, the worse\n",
    "df_declr_misses['trend_relative'] = df_declr_misses.apply(lambda x: x.loc['pct'].diff().sum().round(2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr_misses.columns = df_declr_misses.columns.droplevel()\n",
    "df_declr_misses = df_declr_misses.merge(md_cols.query('table_name == \"declrs\"')[['column_name', 'column_comment']].set_index('column_name'), \n",
    "                      left_index=True, right_index=True, how='left').fillna('')\n",
    "\n",
    "# description\n",
    "df_declr_misses['hm_name'] = df_declr_misses['column_comment'] + ' (' + df_declr_misses.index + ')'\n",
    "\n",
    "logger.debug('Shape of df_declr_misses is {}'.format(df_declr_misses.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declrs_f_seq_complemented = declrs_f_seq.append(df_declr_misses.index[~df_declr_misses.index.isin(declrs_f_seq)])\n",
    "\n",
    "# this is just to mark all rows that they have existed to this point\n",
    "df_declr_misses['C'] = '1'\n",
    "\n",
    "df_declr_misses = df_declr_misses\\\n",
    "    .reindex(declrs_f_seq_complemented)\\\n",
    "    .dropna(subset=['C'])\\\n",
    "    .drop(['C'], axis=1)\\\n",
    "    .drop_duplicates()\\\n",
    "    .copy()\n",
    "\n",
    "logger.debug('Shape of df_declr_misses after the index reorder is {}'.format(df_declr_misses.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy graphs\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(14, 16))\n",
    "\n",
    "ax = axs\n",
    "p = sns.heatmap(df_declr_misses.loc[:, ('hm_name', 2014, 2015, 2016, 2017, 2018)].set_index('hm_name'), \n",
    "                square=False, cmap=plt.get_cmap('OrRd'), ax=ax)\n",
    "\n",
    "p.set_ylabel('')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/declrs_misses_heatmap.pdf')\n",
    "plt.savefig('./images/declrs_misses_heatmap.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy graphs\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8, 12), gridspec_kw={'height_ratios': [1, 20]})\n",
    "\n",
    "ax = axs[0]\n",
    "p = sns.heatmap(df_declr_misses.loc[:, (2014, 2015, 2016, 2017, 2018)].mean().round(1).to_frame().T, \n",
    "                square=False, cmap=plt.get_cmap('OrRd'), \n",
    "                vmin=0, vmax=100, annot=True, fmt='.1f', annot_kws={\"size\": 20}, cbar=True, ax=ax)\n",
    "\n",
    "for t in ax.texts: t.set_text(t.get_text() + \" %\")\n",
    "    \n",
    "ax.set_ylabel('')\n",
    "ax.set_yticklabels(labels='')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=16)\n",
    "\n",
    "# remove cbar\n",
    "# TBC\n",
    "\n",
    "ax = axs[1]\n",
    "p = sns.heatmap(df_declr_misses.loc[:, ('hm_name', 2014, 2015, 2016, 2017, 2018)].set_index('hm_name'), \n",
    "                square=False, cmap=plt.get_cmap('OrRd'), ax=ax)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticklabels('')\n",
    "ax.set_yticklabels('')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/declrs_misses_heatmap_no_labels.png', dpi=150)\n",
    "plt.savefig('./images/declrs_misses_heatmap_no_labels.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2 = pd.read_excel('data/local_db/declr_attrs.xlsx', index_col=0)\n",
    "\n",
    "# completeness\n",
    "dft2 = dft2.merge(100-df_declr_misses.loc[:, (2014, 2015, 2016, 2017, 2018)].round(1), left_index=True, right_index=True, how='left').fillna('-')\n",
    "\n",
    "# report in the format of a TeX table\n",
    "with open('export/90_appendix_A_declr_attributes.tex', 'w', encoding='utf8') as f:\n",
    "    dft2.to_latex(f, longtable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data - Building Level (Declaration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = sa.sql.text('''\n",
    "select d.year,\n",
    "       bld.*,\n",
    "       -- cold water\n",
    "       cw.id cold_water_id, cw.cold_water_type, cw.cold_water_consumption, cw.cold_water_unit, cw.cold_water_payment,\n",
    "       -- hot water\n",
    "       hw.id hot_water_id,  hw.hot_water_type,  hw.hot_water_consumption,  hw.hot_water_unit,  hw.hot_water_payment,\n",
    "       hwj.name hot_water_join_name,\n",
    "       -- cold water\n",
    "       ee.id electric_id,   ee.electric_type,   ee.electric_consumption,   ee.electric_unit,   ee.electric_payment,\n",
    "       -- heat\n",
    "       ht.id heat_id,       ht.heat_type,       ht.heat_consumption,       ht.heat_unit,       ht.heat_payment,\n",
    "       -- OKVED\n",
    "       voc_okved.code main_okved_code, voc_okved.label main_okved_label,\n",
    "       voc_efficiency_class.label efficiency_class_name\n",
    "  from declr_buildings bld \n",
    "       inner join declrs d on bld.id_declr = d.id\n",
    "       inner join orgs o on d.id_org = o.id left join voc_okved on o.id_voc_okved = voc_okved.id\n",
    "       left join voc_building_types   on bld.id_voc_building_type = voc_building_types.id\n",
    "       left join voc_efficiency_class on bld.id_voc_efficiency_class = voc_efficiency_class.id\n",
    "       -- adding the cold water consumption\n",
    "       left join (select *, 'cw' energy_type from declr_cold_water where fake = 0) cw on bld.id = cw.id_declr_building -- and bld.id_declr = heat.id_declr\n",
    "       -- adding the heat consumption\n",
    "       left join (select *, 'hw' energy_type from declr_hot_water  where fake = 0) hw on bld.id = hw.id_declr_building -- and bld.id_declr = heat.id_declr\n",
    "       -- adding the heat consumption\n",
    "       left join (select * from voc_hot_water_join where fake = 0) hwj on bld.id_voc_hot_water_join = hwj.id\n",
    "       left join (select *, 'ee' energy_type from declr_electric   where fake = 0) ee on bld.id = ee.id_declr_building -- and bld.id_declr = heat.id_declr\n",
    "       -- adding the heat consumption\n",
    "       left join (select *, 'ht' energy_type from declr_heat       where fake = 0) ht on bld.id = ht.id_declr_building -- and bld.id_declr = heat.id_declr\n",
    " where d.fake    = 0\n",
    "   and bld.fake  = 0\n",
    "   and o.fake    = 0\n",
    "   and voc_okved.fake = 0\n",
    "   and voc_efficiency_class.fake = 0\n",
    " order by bld.id_declr, bld.id\n",
    "''')\n",
    "\n",
    "df_bld_tmp= pd.read_sql_query(stmt, con=rt.db_engine['energy'])\n",
    "print(df_bld_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld_misses = df_bld_tmp.query('year in (2014, 2015, 2016, 2017, 2018)')\\\n",
    "    .melt(id_vars='year').groupby(['year', 'variable'])\\\n",
    "    .apply(lambda x: round(100*x['value'].isnull().sum()/len(x['value']), 2))\\\n",
    "    .rename('pct')\\\n",
    "    .to_frame().reset_index()\\\n",
    "    .pivot(index='variable', columns='year')\n",
    "\n",
    "# the more value, the worse\n",
    "df_bld_misses['trend_relative'] = df_bld_misses.apply(lambda x: x.loc['pct'].diff().sum().round(2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld_misses.columns = df_bld_misses.columns.droplevel()\n",
    "df_bld_misses = df_bld_misses.merge(md_cols.query('table_name == \"declr_buildings\"')[['column_name', 'column_comment']].set_index('column_name'), \n",
    "                      left_index=True, right_index=True, how='left').fillna('')\n",
    "\n",
    "# description\n",
    "df_bld_misses['hm_name'] = df_bld_misses['column_comment'] + ' (' + df_bld_misses.index + ')'\n",
    "\n",
    "logger.debug('Shape of df_bld_misses is {}'.format(df_bld_misses.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declr_buildings_f_seq_complemented = \\\n",
    "    declr_buildings_f_seq.append(df_bld_misses.index[~df_bld_misses.index.isin(declr_buildings_f_seq)])\n",
    "\n",
    "# this is just to mark all rows that they have existed to this point\n",
    "df_bld_misses['C'] = '1'\n",
    "\n",
    "df_bld_misses = df_bld_misses\\\n",
    "    .reindex(declr_buildings_f_seq_complemented)\\\n",
    "    .dropna(subset=['C'])\\\n",
    "    .drop(['C'], axis=1)\\\n",
    "    .drop_duplicates()\\\n",
    "    .copy()\n",
    "\n",
    "logger.debug('Shape of df_declr_misses after the index reorder is {}'.format(df_bld_misses.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy graphs\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(15, 45))\n",
    "\n",
    "ax = axs\n",
    "p = sns.heatmap(df_bld_misses.loc[:, ('hm_name', 2014, 2015, 2016, 2017, 2018)].set_index('hm_name'), \n",
    "                square=False, cmap=plt.get_cmap('OrRd'), ax=ax)\n",
    "\n",
    "p.set_ylabel('')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/bld_misses_heatmap.pdf')\n",
    "plt.savefig('./images/bld_misses_heatmap.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy graphs\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8, 12), gridspec_kw={'height_ratios': [1, 20]})\n",
    "\n",
    "ax = axs[0]\n",
    "p = sns.heatmap(df_bld_misses.loc[:, (2014, 2015, 2016, 2017, 2018)].mean().round(1).to_frame().T, \n",
    "                square=False, cmap=plt.get_cmap('OrRd'), \n",
    "                vmin=0, vmax=100, annot=True, fmt='.1f', annot_kws={\"size\": 20}, cbar=True, ax=ax)\n",
    "\n",
    "for t in ax.texts: t.set_text(t.get_text() + \" %\")\n",
    "    \n",
    "ax.set_ylabel('')\n",
    "ax.set_yticklabels(labels='')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=16)\n",
    "\n",
    "# remove cbar\n",
    "# TBC\n",
    "\n",
    "ax = axs[1]\n",
    "p = sns.heatmap(df_bld_misses.loc[:, ('hm_name', 2014, 2015, 2016, 2017, 2018)].set_index('hm_name'), \n",
    "                square=False, cmap=plt.get_cmap('OrRd'), ax=ax)\n",
    "\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticklabels('')\n",
    "ax.set_yticklabels('')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/bld_misses_heatmap_no_labels.png', dpi=150)\n",
    "plt.savefig('./images/bld_misses_heatmap_no_labels.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2 = pd.read_excel('data/local_db/bld_attrs.xlsx', index_col=0)\n",
    "\n",
    "# completeness\n",
    "dft2 = dft2.merge(100-df_bld_misses.loc[:, (2014, 2015, 2016, 2017, 2018)].round(1), left_index=True, right_index=True, how='left').fillna('-')\n",
    "\n",
    "# report in the format of a TeX table\n",
    "with open('export/90_appendix_A_bld_attributes.tex', 'w', encoding='utf8') as f:\n",
    "    dft2.to_latex(f, longtable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_bld_tmp[['year', 'cold_water_consumption']]\\\n",
    "    .groupby('year')['cold_water_consumption'].apply(lambda x: x.isna().mean()).to_frame().T\n",
    "\n",
    "dft = dft.round(4)*100\n",
    "\n",
    "# fancy graphs\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(4, 1))\n",
    "\n",
    "ax = axs\n",
    "sns.heatmap(dft, square=False, cmap=plt.get_cmap('OrRd'), \n",
    "            vmin=0, vmax=100, annot=True, fmt='.1f', annot_kws={\"size\": 12}, cbar=False, ax=ax)\n",
    "\n",
    "for t in ax.texts: t.set_text(t.get_text() + \" %\")\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_yticklabels(labels='')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/cw_misses.png', dpi=150)\n",
    "plt.savefig('./images/cw_misses.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_bld_tmp.query('hot_water_join_name != \"none\" and hot_water_join_name == hot_water_join_name')[['year', 'hot_water_consumption']]\\\n",
    "    .groupby('year')['hot_water_consumption'].apply(lambda x: x.isna().mean()).to_frame().T\n",
    "\n",
    "dft = dft.round(4)*100\n",
    "\n",
    "# fancy graphs\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(4, 1))\n",
    "\n",
    "ax = axs\n",
    "sns.heatmap(dft, square=False, cmap=plt.get_cmap('OrRd'), \n",
    "            vmin=0, vmax=100, annot=True, fmt='.1f', annot_kws={\"size\": 12}, cbar=False, ax=ax)\n",
    "\n",
    "for t in ax.texts: t.set_text(t.get_text() + \" %\")\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_yticklabels(labels='')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/hw_misses.png', dpi=150)\n",
    "plt.savefig('./images/hw_misses.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_bld_tmp[['year', 'electric_consumption']]\\\n",
    "    .groupby('year')['electric_consumption'].apply(lambda x: x.isna().mean()).to_frame().T\n",
    "\n",
    "dft = dft.round(4)*100\n",
    "\n",
    "# fancy graphs\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(4, 1))\n",
    "\n",
    "ax = axs\n",
    "sns.heatmap(dft, square=False, cmap=plt.get_cmap('OrRd'), \n",
    "            vmin=0, vmax=100, annot=True, fmt='.1f', annot_kws={\"size\": 12}, cbar=False, ax=ax)\n",
    "\n",
    "for t in ax.texts: t.set_text(t.get_text() + \" %\")\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_yticklabels(labels='')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/ee_misses.png', dpi=150)\n",
    "plt.savefig('./images/ee_misses.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_bld_tmp.query('heated_area > 0')[['year', 'heat_consumption']]\\\n",
    "    .groupby('year')['heat_consumption'].apply(lambda x: x.isna().mean()).to_frame().T\n",
    "\n",
    "dft = dft.round(4)*100\n",
    "\n",
    "# fancy graphs\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(4, 1))\n",
    "\n",
    "ax = axs\n",
    "sns.heatmap(dft, square=False, cmap=plt.get_cmap('OrRd'), \n",
    "            vmin=0, vmax=100, annot=True, fmt='.1f', annot_kws={\"size\": 12}, cbar=False, ax=ax)\n",
    "\n",
    "for t in ax.texts: t.set_text(t.get_text() + \" %\")\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_yticklabels(labels='')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./images/ht_misses.png', dpi=150)\n",
    "plt.savefig('./images/ht_misses.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "sheets = {'Декларации - Общее':  {'data': df_declr_misses},\n",
    "          'Декларации - Здания': {'data': df_bld_misses}}\n",
    "\n",
    "file_name = './export/%s' % 'missing_data_stats.xlsx'\n",
    "\n",
    "xls_writer = pd.ExcelWriter(file_name,\n",
    "                            engine='xlsxwriter',\n",
    "                            options={'strings_to_urls': False})  # 'strings_to_numbers': True\n",
    "\n",
    "logger.info('Saving to %s' % file_name)\n",
    "\n",
    "for key, val in sheets.items():\n",
    "\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    sheet_name = key\n",
    "\n",
    "    val['data'].reset_index().to_excel(xls_writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "    # Set the column width and format.\n",
    "    workbook  = xls_writer.book\n",
    "    worksheet = xls_writer.sheets[sheet_name]\n",
    "    sheet_data_range = (string.ascii_uppercase[0] + '1', \n",
    "                        string.ascii_uppercase[val['data'].shape[1]] + str(val['data'].shape[0] + 1))\n",
    "    worksheet.set_column('A:A', width = 40,  cell_format = workbook.add_format().set_align('left'))\n",
    "    worksheet.set_column('B:F', width = 10,  cell_format = workbook.add_format().set_align('center'))\n",
    "    worksheet.set_column('G:G', width = 100, cell_format = workbook.add_format().set_align('left'))\n",
    "    \n",
    "    # Set the autofilter.\n",
    "    worksheet.autofilter('%s:%s' % sheet_data_range)\n",
    "\n",
    "xls_writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx-small, x-small, small, medium, large, x-large, xx-large, larger, smaller\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "LARGE_SIZE = 14\n",
    "\n",
    "plt.rc('font',   size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes',   titlesize=LARGE_SIZE)      # fontsize of the axes title\n",
    "plt.rc('axes',   labelsize=LARGE_SIZE)      # fontsize of the x and y labels\n",
    "plt.rc('xtick',  labelsize=LARGE_SIZE)      # fontsize of the tick labels\n",
    "plt.rc('ytick',  labelsize=LARGE_SIZE)      # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=LARGE_SIZE)       # legend fontsize\n",
    "plt.rc('figure', titlesize=LARGE_SIZE)      # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr['year'].value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr['year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr[df_declr['employees'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "df_declr.groupby('year')['year'].count().plot(kind='bar', ax=ax)\n",
    "df_declr.groupby('year')['id_org'].count().plot(kind='bar', ax=ax)\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Количество деклараций')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Number of declarations')\n",
    "    \n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/declrs_by_years.png', dpi=300)\n",
    "fig.savefig('images/declrs_by_years.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_declr.groupby('year')['total_consumption_tut'].sum()/1000000\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Потребление топлива, млн. т.у.т.')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Energy consumption, mln. t.u.t.')\n",
    "    \n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "ax.yaxis.set_major_formatter(plt.FormatStrFormatter('%.1f'))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/declrs_tut_by_years.png', dpi=300)\n",
    "fig.savefig('images/declrs_tut_by_years.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "df_bld.groupby('year')['year'].count().plot(kind='bar', ax=ax)\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Количество зданий')\n",
    "elif LANG == 'en':    \n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Number of buildings')\n",
    "    \n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_by_years.png', dpi=300)\n",
    "fig.savefig('images/bld_by_years.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld[df_bld['employees'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bld[df_bld['guests'] == 0].shape[0]/len(df_bld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floor Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_bld.groupby('year')['floor_area'].sum()/10000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Общая площадь, млн. кв. м')\n",
    "elif LANG == 'en':     \n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Floor area, mln. of square meters')\n",
    "    \n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_floor_area_years.png', dpi=300)\n",
    "fig.savefig('images/bld_floor_area_years.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld.groupby('year')['floor_area'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for any buildings with unusually high heated_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld.sort_values('floor_area', ascending=False).head(5)[['id_org', 'floor_area']]\\\n",
    "    .merge(df_org[['label']], left_on='id_org', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gov_eneff import preprocessing\n",
    "bld_filter_set = preprocessing.BldFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = bld_filter_set.f1(df_bld) #.groupby('year')['heated_area'].sum()[['year', 'heated_area']]\n",
    "dft.groupby('year')['floor_area'].mean().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_bld.groupby('year')['heated_area'].sum()/10000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Отапливаемая площадь, млн. кв. м')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Heated area, mln. squared meters')\n",
    "    \n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_heated_area_years.png', dpi=300)\n",
    "fig.savefig('images/bld_heated_area_years.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld.groupby('year')['heated_area'].mean().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld.groupby('year')['heated_area'].median().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "#dft = df_bld.query('heated_area <= 100000')\n",
    "dft = df_bld.query('heated_area > 0 and heated_area == heated_area').copy()\n",
    "dft['heated_area_log10'] = np.log10(dft['heated_area'])\n",
    "\n",
    "#sns.catplot(x='year', y='heated_area_log10', data=dft, kind='violin') #, width=0.6)\n",
    "sns.boxplot(x='year', y='heated_area_log10', data=dft, width=0.6, color='#33CC66')\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Отапливаемая площадь, млн. кв. м')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('$log_{10}{heated\\_area}$')\n",
    "    \n",
    "#plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "ax.set_yticks(range(8))\n",
    "#ax.set_yticklabels([str(n) for n in range(7)])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_heated_area_years_boxplot.png', dpi=300)\n",
    "fig.savefig('images/bld_heated_area_years_boxplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "#dft = df_bld.query('heated_area <= 100000')\n",
    "dft = df_bld.query('heated_area > 0 and heated_area == heated_area').copy()\n",
    "dft['heated_area_log10'] = np.log10(dft['heated_area'])\n",
    "\n",
    "#sns.catplot(x='year', y='heated_area_log10', data=dft, kind='violin') #, width=0.6)\n",
    "sns.boxplot(x='year', y='heated_area_log10', data=dft, width=0.6, color='#33CC66')\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Отапливаемая площадь, млн. кв. м')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('$log_{10}{heated\\_area}$')\n",
    "    \n",
    "#plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "ax.set_yticks(range(8))\n",
    "#ax.set_yticklabels([str(n) for n in range(7)])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_heated_area_years_boxplot.png', dpi=300)\n",
    "fig.savefig('images/bld_heated_area_years_boxplot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Geo Distribution\n",
    "\n",
    "- Geomapping, GDAL for Windows: https://sandbox.idre.ucla.edu/sandbox/tutorials/installing-gdal-for-windows\n",
    "\n",
    "Maps: \n",
    "- https://data.nextgis.com/ru/\n",
    "- http://gisgeo.org/data.html\n",
    "- http://download.geofabrik.de/russia.html\n",
    "- https://habr.com/ru/post/321710/\n",
    "- https://wiki.openstreetmap.org/wiki/Shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(9/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 7))\n",
    "\n",
    "dft = df_bld[['dd_geo_lat', 'dd_geo_lon', 'dd_okved_code_l1']].drop_duplicates()\n",
    "print(dft.shape)\n",
    "print((dft['dd_geo_lat'].max()-dft['dd_geo_lat'].min())/(dft['dd_geo_lon'].max()-dft['dd_geo_lon'].min()))\n",
    "print(dft['dd_geo_lat'].isna().mean())\n",
    "\n",
    "# jittering\n",
    "jitter_size = 0.05\n",
    "dft['dd_geo_lat'] = dft['dd_geo_lat'] + np.random.uniform(low=-jitter_size, high=+jitter_size, size=len(dft))\n",
    "dft['dd_geo_lon'] = dft['dd_geo_lon'] + np.random.uniform(low=-jitter_size, high=+jitter_size, size=len(dft))\n",
    "\n",
    "sns.scatterplot(data=dft, x='dd_geo_lon', y='dd_geo_lat', hue='dd_okved_code_l1', marker='+',\n",
    "                alpha=0.7, ax=ax) #, palette=diverging_colors)\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Долгота')\n",
    "    ax.set_ylabel('Широта')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "ax.legend([])\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_geo_naive.png', dpi=300)\n",
    "fig.savefig('images/bld_geo_naive.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the filepath and load in a shapefile\n",
    "fp = \"maps/Moscow_region.shp\"\n",
    "\n",
    "map_df = gpd.read_file(fp, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data type so we can see that this is not a normal dataframe, but a GEOdataframe\n",
    "map_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df.geometry.bounds['minx'].min()*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['ya_geo_lon'] = df_bld['ya_geo_pos'].apply(lambda x: float(x.split(' ')[0]) if pd.notna(x) else np.nan)\n",
    "df_bld['ya_geo_lat'] = df_bld['ya_geo_pos'].apply(lambda x: float(x.split(' ')[1]) if pd.notna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's preview what our map looks like with no data in it\n",
    "#https://github.com/bendoesdata/make-a-map-geopandas/blob/master/Let's%20make%20a%20map!%20Geopandas%20and%20Matplotlib.ipynb\n",
    "\n",
    "import pyproj\n",
    "\n",
    "# yandex geocoder provide the geo information on more objects\n",
    "geocoder = 'yandex'\n",
    "\n",
    "if geocoder == 'dadata':\n",
    "    # case 1: DaData\n",
    "    df_bld['geo_lon'], df_bld['geo_lat'] = df_bld['dd_geo_lon'], df_bld['dd_geo_lat']\n",
    "elif geocoder == 'yandex':\n",
    "    # case 2: Yandex\n",
    "    df_bld['geo_lon'], df_bld['geo_lat'] = df_bld['ya_geo_lon'], df_bld['ya_geo_lat']\n",
    "\n",
    "dft = df_bld[['geo_lon', 'geo_lat', 'dd_okved_code_l1']].drop_duplicates()\n",
    "print(dft.shape)\n",
    "#print((dft['dd_geo_lat'].max()-dft['dd_geo_lat'].min())/(dft['dd_geo_lon'].max()-dft['dd_geo_lon'].min()))\n",
    "#print(dft['dd_geo_lat'].isna().mean())\n",
    "\n",
    "# jittering\n",
    "jitter_size = 0.02\n",
    "dft['geo_lon'] = dft['geo_lon'] + np.random.uniform(low=-jitter_size, high=+jitter_size, size=len(dft))\n",
    "# for some reason the -0.2 offset is required to place points to where they seem to belong\n",
    "dft['geo_lat'] = dft['geo_lat'] + np.random.uniform(low=-jitter_size, high=+jitter_size, size=len(dft)) - 0.2\n",
    "\n",
    "# https://data.nextgis.com/ru/faq/\n",
    "# Данные находятся в системе координат - широта/долгота WGS84 (EPSG: 4326). \n",
    "# Система координат отображения данных, используемая для проектов Mercator - EPSG: 3857.\n",
    "inProj  = pyproj.Proj(init='epsg:4326')\n",
    "outProj = pyproj.Proj(init='epsg:3857')\n",
    "\n",
    "dft['geo_lon_3857'], dft['geo_lat_3857'] = pyproj.transform(inProj, outProj, \n",
    "                                                              dft['geo_lon'].to_numpy(), \n",
    "                                                              dft['geo_lat'].to_numpy())\n",
    "\n",
    "# moving all points which are too far from the map to the bounds\n",
    "minx = map_df.geometry.bounds['minx'].min()\n",
    "dft['geo_lon_3857'] = dft['geo_lon_3857'].apply(lambda x: minx if x < minx else x)\n",
    "maxx = map_df.geometry.bounds['maxx'].max()\n",
    "dft['geo_lon_3857'] = dft['geo_lon_3857'].apply(lambda x: maxx if x > maxx else x)\n",
    "miny = map_df.geometry.bounds['miny'].min()\n",
    "dft['geo_lat_3857'] = dft['geo_lat_3857'].apply(lambda y: miny if y < miny else y)\n",
    "maxy = map_df.geometry.bounds['maxy'].max()\n",
    "dft['geo_lat_3857'] = dft['geo_lat_3857'].apply(lambda y: maxy if y > maxy else y)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "\n",
    "map_df.plot(ax=ax, linewidth=0.8, edgecolor='0.5', color='white')\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "sns.scatterplot(data=dft, x='geo_lon_3857', y='geo_lat_3857', hue='dd_okved_code_l1', marker='+',\n",
    "                alpha=0.7, ax=ax) #, palette=diverging_colors)\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Долгота')\n",
    "    ax.set_ylabel('Широта')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "ax.legend([])\n",
    "\n",
    "fig.savefig(f'images/bld_geo_{geocoder}.png', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "fig.savefig(f'images/bld_geo_{geocoder}.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(8, 5), gridspec_kw = {'height_ratios':[7, 1]})\n",
    "\n",
    "dft = df_bld.query('building_age <= 150')['building_age']\n",
    "\n",
    "ax_dp = axs[0]\n",
    "sns.distplot(dft, ax=ax_dp, bins=50)\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax_dp.set_xlabel('Возраст здания')\n",
    "    ax_dp.set_ylabel('Плотность распреления')\n",
    "elif LANG == 'en':\n",
    "    ax_dp.set_xlabel('Age')\n",
    "    ax_dp.set_ylabel('Density')\n",
    "    \n",
    "ax_bp = axs[1]\n",
    "\n",
    "sns.boxplot(dft, ax=ax_bp)\n",
    "ax_bp.set_xlabel('')\n",
    "ax_bp.set_xlim(ax_dp.get_xlim())\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_age.png', dpi=300)\n",
    "fig.savefig('images/bld_age.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKVED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability of declrs.main_okved - Poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of organizations changed their main OKVED over the years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there organization which have changed their main OKVED over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organization which have changed their main OKVED over the years\n",
    "dft = df_declr[~df_declr['main_okved'].isnull()][['id_org', 'main_okved']].drop_duplicates()\\\n",
    "    .groupby(['id_org'])['id_org', 'main_okved']\\\n",
    "    .filter(lambda x: len(x.drop_duplicates()) > 1)\\\n",
    "    .sort_values('id_org')['id_org'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dft))\n",
    "print(100*len(dft)/len(df_declr[~df_declr['main_okved'].isnull()]['id_org'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr_okved_amb = df_declr.query('id_org in @dft')[['id_org', 'year', 'main_okved']]\n",
    "print(df_declr_okved_amb.shape)\n",
    "# drop records with the missing OKVED\n",
    "df_declr_okved_amb = df_declr_okved_amb[df_declr_okved_amb['main_okved'].notna()]\n",
    "print(df_declr_okved_amb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr_okved_amb.pivot(index='id_org', columns='year').sample(10).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection of OKVED and OKVED2\n",
    "stmt = sa.sql.text('''\n",
    "select code\n",
    "  from voc_okved\n",
    " where code != ''\n",
    "   and fake = 0  \n",
    "intersect\n",
    "select code\n",
    "  from voc_okved2\n",
    " where code != ''\n",
    "   and fake = 0\n",
    "''')\n",
    "okved12_intersect = pd.read_sql_query(stmt, con=rt.db_engine['energy'])\n",
    "print(okved12_intersect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check whether we can still get away with matching all missing codes solely to OKVED\n",
    "# the idea is to check whether for any case with the mixed codes there are no entries of the codes in both OKVED and OKVED2\n",
    "\n",
    "# there should be zero records if there are no such codes\n",
    "print(len(df_declr_okved_amb[df_declr_okved_amb['main_okved'].isin(okved12_intersect['code'])]))\n",
    "\n",
    "# unfortunately, it's not possible to remove ambiguity\n",
    "\n",
    "# df_declr_okved_amb.merge(df_okved[['code', 'label']].set_index('code'), \n",
    "#                           left_on='main_okved', right_index=True, how='left')\\\n",
    "#     .dropna()\\\n",
    "#     .sort_values(['id_org', 'year'])\\\n",
    "#     .groupby(['id_org'])['main_okved'].apply(lambda x: x.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr_okved_amb.query('id_org == 6972')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr.query('id_org == 6972')['inn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take the dummy approach - pick up the most earliest known main_okved value, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of OKVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_bld[['id_org', 'dd_okved_code_l1']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_red_high_values(val):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: red'` for large\n",
    "    values, black otherwise.\n",
    "    \"\"\"\n",
    "    color = 'red' if val >= 10 else 'black'\n",
    "    return('color: %s' % color)\n",
    "\n",
    "dft = df_bld[['id_org', 'dd_okved_code_l1']].drop_duplicates()\n",
    "dft.groupby('dd_okved_code_l1').apply(lambda x: round(100*len(x)/len(dft), 1)).to_frame()\\\n",
    "    .rename(columns={0: 'pcts'})\\\n",
    "    .merge(db.df_okved2[db.df_okved2['code'].str.len() == 2][['code', 'label']].sort_values('code').set_index('code'),\n",
    "           left_index=True, right_index=True, how='left')\\\n",
    "    .sort_index(ascending=True)\n",
    "#    .style.apply(lambda x: 'color: red' if x >= 10 else 'color: black', subset=['pcts'], axis=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['dd_okved'].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld['dd_okved_code_l1'].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "dft = df_bld.query('dd_okved_code_l1 != \"\"')[['id_org', 'dd_okved_code_l1']].groupby('dd_okved_code_l1').agg('count')\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Код ОКВЭД2 (уровень 1)')\n",
    "    ax.set_ylabel('Количество организаций')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('OKVED (level 1)')\n",
    "    ax.set_ylabel('Number of organizations')\n",
    "    \n",
    "#plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "ax.legend([])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/org_okved_l1.png', dpi=300)\n",
    "fig.savefig('images/org_okved_l1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Distribution of Factors per OKVED (to Excel)\n",
    "\n",
    "Per each popular OKVED per each year, estimate the distribution of some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_list = ['total_consumption_tut', 'total_consumption_tut_per_emp', 'employees', 'guests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_declr['total_consumption_tut_per_emp'] = df_declr['total_consumption_tut'] / df_declr['employees'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_distribution(data, round_precision=1):\n",
    "    \n",
    "    res = {}\n",
    "    \n",
    "    res['count_all']     = len(data)\n",
    "    res['count_values']  = data.count()\n",
    "    res['count_nulls']   = data.isnull().sum()\n",
    "    res['min']      = data.min()\n",
    "    res['q01']      = data.quantile(.01)\n",
    "    res['q05']      = data.quantile(.05)\n",
    "    res['q10']      = data.quantile(.10)\n",
    "    res['median']   = data.median()\n",
    "    res['mean']     = data.mean()\n",
    "    res['q90']      = data.quantile(.90)\n",
    "    res['q95']      = data.quantile(.95)\n",
    "    res['q99']      = data.quantile(.99)\n",
    "    res['max']      = data.max()\n",
    "    \n",
    "    # logger.debug(type(res['q10']))\n",
    "    \n",
    "    for k, v in res.items():\n",
    "        if type(v) in(float, np.float64):\n",
    "            res[k] = round(v, round_precision)\n",
    "    \n",
    "    return(pd.Series(res))\n",
    "\n",
    "def get_rugplot_sns(data, xmedian, xlim=None):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, figsize=(5, .25))\n",
    "    \n",
    "    ax = axs\n",
    "    \n",
    "    sns.rugplot(data, height=1, ax=ax, linewidth=2, alpha=0.7)\n",
    "    ax.vlines(x=xmedian, ymin=0, ymax=1, colors='red', linewidth=1)\n",
    "    \n",
    "    if xlim is None:\n",
    "        pass\n",
    "    else:\n",
    "        if xlim == 'auto':\n",
    "            xleft  = data[~np.isneginf(data)].min()\n",
    "            xright = data[~np.isposinf(data)].max()\n",
    "            # logger.debug('{} {}'.format(xleft, xright))\n",
    "        elif type(xlim) in {list, tuple}:\n",
    "            xleft  = xlim[0]\n",
    "            xright = xlim[1]\n",
    "            xlim = ax.set_xlim([xleft, xright])\n",
    "        else:\n",
    "            raise TypeError('Unknown type for xlim')\n",
    "            \n",
    "        if not np.isnan(xleft) and not np.isnan(xright):            \n",
    "            \n",
    "            plt.subplots_adjust(left=0.1, right=0.8)            \n",
    "\n",
    "            plt.gcf().text(0.0,  0.25, '{:.1f}'.format(xleft),  fontsize='x-small')\n",
    "            plt.gcf().text(0.82, 0.25, '{:.1f}'.format(xright), fontsize='x-small')\n",
    "    \n",
    "    ylim = ax.set_ylim([0, 1])\n",
    "    \n",
    "    yticks = ax.set_yticks([])\n",
    "    yticklabels = ax.set_yticklabels([])\n",
    "    xticks = ax.set_xticks([])\n",
    "    xticklabels = ax.set_xticklabels([])\n",
    "           \n",
    "    ax.tick_params(axis='both', which='major', labelsize='x-small')\n",
    "    ax.tick_params(axis='both', which='minor', labelsize='x-small')\n",
    "   \n",
    "    [item[1].set_linewidth(0.2)  for item in ax.spines.items()]\n",
    "    [item[1].set_edgecolor('black')  for item in ax.spines.items()]\n",
    "    [item[1].set_visible(True) for item in ax.spines.items()]\n",
    "    \n",
    "    #fig.set_frameon(False)\n",
    "    #plt.autoscale(tight=True)\n",
    "    #plt.subplots_adjust(top=1, bottom=0)\n",
    "    \n",
    "    #fig.tight_layout(pad=0)\n",
    "           \n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', dpi=300, bbox_inches='tight', pad_inches=0, transparent=False)    \n",
    "    buf.seek(0)    \n",
    "    imgdata = buf.getvalue()\n",
    "    buf.close()\n",
    "    plt.close()\n",
    "    \n",
    "    return(imgdata)\n",
    "\n",
    "\n",
    "# the function below is not quite complete\n",
    "def get_rugplot_mpl(data, xmedian, xlim=None):\n",
    "    \n",
    "    ax = axs\n",
    "    \n",
    "    with plt.style.context('ggplot', after_reset=True):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(4, 0.25))\n",
    "        ax.plot(data, [0]*len(data), marker='|', markersize=200, color='black', linestyle=' ', alpha=0.5)\n",
    "        \n",
    "        yticks = ax.set_yticks([])\n",
    "        yticklabels = ax.set_yticklabels([])\n",
    "        # xticklabels = ax.set_xticklabels([])\n",
    "        \n",
    "        ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=7)\n",
    "        \n",
    "        # marking the median\n",
    "        ax.vlines(x=xmedian, ymin=0, ymax=1, colors='red', linewidth=1)\n",
    "    \n",
    "        [item[1].set_linewidth(0.2)  for item in ax.spines.items()]\n",
    "        [item[1].set_edgecolor('black')  for item in ax.spines.items()]\n",
    "        [item[1].set_visible(True) for item in ax.spines.items()]\n",
    "    \n",
    "        if xlim != None:\n",
    "            ax.set_xlim(xlim)\n",
    "\n",
    "        ylim = ax.set_ylim([0, 1])\n",
    "        \n",
    "        buf = io.BytesIO()\n",
    "        # fig.tight_layout()\n",
    "        plt.savefig(buf, format='png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "\n",
    "        buf.seek(0)    \n",
    "        imgdata = buf.getvalue()\n",
    "        buf.close()\n",
    "        plt.close()\n",
    "            \n",
    "    return(imgdata)\n",
    "\n",
    "\n",
    "def get_rugplot(data, xmedian, xlim=None):\n",
    "    \n",
    "    return(get_rugplot_sns(data, xmedian, xlim))\n",
    "\n",
    "# taking only the most popular okved's\n",
    "okved_no_threshold = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the distributions and listing the outliers for the **whole** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df_declr.groupby(['year', 'main_okved']).filter(lambda x: len(x) >= okved_no_threshold)\\\n",
    "    .groupby(['main_okved', 'year'])\n",
    "\n",
    "# dictionary of data frame by var names\n",
    "df_dict = {}\n",
    "\n",
    "# estimating the distribution by main_okved, year\n",
    "for var_name in vars_list:\n",
    "    df_dict[var_name] = dfg[var_name].apply(lambda x: est_distribution(x)).to_frame().unstack()\n",
    "    df_dict[var_name].columns = df_dict[var_name].columns.get_level_values(1)\n",
    "    #df_dict[var_name]['var_name'] = var_name\n",
    "    \n",
    "#df_declr_dist = df_dict[vars_list[0]]\n",
    "\n",
    "#for var_name in vars_list[1:]:\n",
    "#    df_declr_dist = df_declr_dist.join(df_dict[var_name])\n",
    "\n",
    "df_declr_dist = pd.concat(df_dict, axis=0)\n",
    "\n",
    "# adding the rugplot\n",
    "\n",
    "# the levels: 0 - var_name, 1 - okved, 2 - year\n",
    "df_declr_dist['plot'] = \\\n",
    "    df_declr_dist.apply(lambda x: get_rugplot(df_declr.query('main_okved == \"%s\" and year == %s' % (x.name[1], x.name[2]))[x.name[0]].to_numpy(), \n",
    "                                              xmedian=x['median']),\n",
    "                        axis=1)\n",
    "\n",
    "                           \n",
    "df_declr_outliers_dict = {}\n",
    "\n",
    "# building the list of outliers\n",
    "for var_name in vars_list:\n",
    "    df_declr_outliers_dict[var_name] = df_declr.merge(df_declr_dist.loc[var_name], \n",
    "                                                      left_on=['main_okved', 'year'], \n",
    "                                                      right_index=True)\\\n",
    "        .query('%s < q01 or %s > q99' % (var_name, var_name))\\\n",
    "        [['year', 'main_okved', 'main_okved_label', 'id_org', 'company_name', 'actual_address', \n",
    "          var_name, \n",
    "          'q01', 'median', 'mean', 'q99']].sort_values(['id_org', 'year'])\n",
    "    \n",
    "    \n",
    "# adding additional attributes to the distribution stats\n",
    "print(df_declr_dist.shape)\n",
    "df_declr_dist = df_declr_dist.merge(db.df_okved[['code', 'label']].set_index('code').rename(columns={'label': 'main_okved_label'}), \n",
    "                                    left_on='main_okved', right_index=True, how='left')\n",
    "# forward the required columns\n",
    "df_declr_dist = df_declr_dist.reindex(columns=pd.Index(['main_okved_label']).append( df_declr_dist.columns.difference(['main_okved_label'])))\n",
    "print(df_declr_dist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the distributions and listing the outliers for a subset (within the quantiles 0.1-0.9) per each variable per each main_okved and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg2 = df_declr.groupby(['year', 'main_okved'])\\\n",
    "    .filter(lambda x: len(x) >= okved_no_threshold).groupby(['main_okved', 'year'])\n",
    "\n",
    "# dictionary of data frame by var names\n",
    "df_dict2 = {}\n",
    "\n",
    "# estimating the distribution by main_okved, year\n",
    "for var_name in vars_list:\n",
    "    df_dict2[var_name] = dfg2[var_name]\\\n",
    "        .apply(lambda x: est_distribution(x[(x >= df_declr_dist.loc[(var_name, x.name[0], x.name[1])]['q10']) & \\\n",
    "                                            (x <= df_declr_dist.loc[(var_name, x.name[0], x.name[1])]['q90'])])).to_frame().unstack()\n",
    "    df_dict2[var_name].columns = df_dict2[var_name].columns.get_level_values(1)\n",
    "    #df_dict[var_name]['var_name'] = var_name\n",
    "    \n",
    "#df_declr_dist = df_dict[vars_list[0]]\n",
    "\n",
    "#for var_name in vars_list[1:]:\n",
    "#    df_declr_dist = df_declr_dist.join(df_dict[var_name])\n",
    "\n",
    "df_declr_dist2 = pd.concat(df_dict2, axis=0)\n",
    "\n",
    "# adding the rugplot\n",
    "\n",
    "def invoke_get_rugplot(x):\n",
    "    \n",
    "    (var_name, main_okved, year) = x.name\n",
    "    ql = df_declr_dist.loc[x.name]['q10']\n",
    "    qh = df_declr_dist.loc[x.name]['q90']\n",
    "    median = x['median']\n",
    "    xleft  = df_declr_dist2.loc[(var_name, main_okved)]['min'].replace([np.inf, -np.inf], np.nan).min()\n",
    "    xright = df_declr_dist2.loc[(var_name, main_okved)]['max'].replace([np.inf, -np.inf], np.nan).max()\n",
    "    \n",
    "    # logger.debug('{} {} {} {:.1f} {:.1f}'.format(var_name, main_okved, year, xleft, xright))\n",
    "    \n",
    "    x = df_declr.query('main_okved == \"{main_okved}\" and year == {year} and {var_name} >= {ql} and {var_name} <= {qh}'\\\n",
    "                                    .format(var_name=var_name,\n",
    "                                            main_okved=main_okved, \n",
    "                                            year=year, \n",
    "                                            ql=ql,\n",
    "                                            qh=qh))[var_name].to_numpy()\n",
    "    \n",
    "    imgdata = get_rugplot(x, xmedian=median, xlim=(xleft, xright))\n",
    "\n",
    "    return(imgdata)\n",
    "\n",
    "df_declr_dist2['plot'] = df_declr_dist2.apply(lambda x: invoke_get_rugplot(x), axis=1)\n",
    "\n",
    "\n",
    "df_declr_outliers_dict2 = {}\n",
    "\n",
    "# building the list of outliers\n",
    "for var_name in vars_list:\n",
    "    df_declr_outliers_dict2[var_name] = df_declr.merge(df_declr_dist2.loc[var_name], \n",
    "                                                       left_on=['main_okved', 'year'], \n",
    "                                                       right_index=True)\\\n",
    "        .query('%s < q10 or %s > q90' % (var_name, var_name))\\\n",
    "        [['year', 'main_okved', 'main_okved_label','id_org', 'company_name', 'actual_address', \n",
    "          var_name, \n",
    "          'q10', 'median', 'mean', 'q90']].sort_values(['id_org', 'year'])\n",
    "    \n",
    "    \n",
    "# adding additional attributes to the distribution stats\n",
    "print(df_declr_dist2.shape)\n",
    "df_declr_dist2 = df_declr_dist2.merge(db.df_okved[['code', 'label']].set_index('code').rename(columns={'label': 'main_okved_label'}), \n",
    "                                     left_on='main_okved', right_index=True, how='left')\n",
    "# forward the required columns\n",
    "df_declr_dist2 = df_declr_dist2.reindex(columns=pd.Index(['main_okved_label']).append( df_declr_dist2.columns.difference(['main_okved_label'])))\n",
    "print(df_declr_dist2.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_declr.query('main_okved == \"{main_okved}\" and year == {year} and {var_name} >= {ql} and {var_name} <= {qh}'\\\n",
    "#           .format(main_okved=\"75.11.31\", \n",
    "#                   year=2014, \n",
    "#                   var_name='employees',\n",
    "#                   ql=0.5,\n",
    "#                   qh=20.5))['employees'].to_numpy()\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "# imgdata = get_rugplot(data, xmedian=10, xlim=(6, 30))\n",
    "\n",
    "# im = Image.open(io.BytesIO(imgdata))\n",
    "# im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of image retrieval\n",
    "\n",
    "# from PIL import Image\n",
    "# buf = io.BytesIO(df_declr_dist2.loc[('employees', '75.11.31', 2014)]['plot'])\n",
    "# im = Image.open(buf)\n",
    "# im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "exports = {'All': \n",
    "             {\n",
    "             'file_name': './export/{}'.format('activity_factors_distr_by_okved_all.xlsx'),\n",
    "             'sheets':   {\n",
    "                  '1. Оц. распр. tct':          {'data': df_declr_dist.loc['total_consumption_tut'].reset_index()},\n",
    "                  '1. Оц. распр. tct_per_emp':  {'data': df_declr_dist.loc['total_consumption_tut_per_emp'].reset_index()},\n",
    "                  '1. Оц. распр. employees':    {'data': df_declr_dist.loc['employees'].reset_index()},\n",
    "                  '1. Оц. распр. guests':       {'data': df_declr_dist.loc['guests'].reset_index()},          \n",
    "                  '1. Выбросы по ttt':          {'data': df_declr_outliers_dict['total_consumption_tut']},\n",
    "                  '1. Выбросы по ttt_per_emp':  {'data': df_declr_outliers_dict['total_consumption_tut_per_emp']},\n",
    "                  '1. Выбросы по employees':    {'data': df_declr_outliers_dict['employees']},\n",
    "                  '1. Выбросы по guests':       {'data': df_declr_outliers_dict['guests']},\n",
    "                 }\n",
    "             },\n",
    "          'Subset1':\n",
    "             {\n",
    "             'file_name': './export/{}'.format('activity_factors_distr_by_okved_without_outliers.xlsx'),\n",
    "             'sheets':   {\n",
    "                  '2. Оц. распр. tct':          {'data': df_declr_dist2.loc['total_consumption_tut'].reset_index()},\n",
    "                  '2. Оц. распр. tct_per_emp':  {'data': df_declr_dist2.loc['total_consumption_tut_per_emp'].reset_index()},\n",
    "                  '2. Оц. распр. employees':    {'data': df_declr_dist2.loc['employees'].reset_index()},\n",
    "                  '2. Оц. распр. guests':       {'data': df_declr_dist2.loc['guests'].reset_index()}\n",
    "                 }\n",
    "             }\n",
    "         }\n",
    "                 \n",
    "for export_type, export_config in exports.items():\n",
    "\n",
    "    file_name = export_config['file_name']\n",
    "\n",
    "    xls_writer = pd.ExcelWriter(file_name,\n",
    "                                engine='xlsxwriter',\n",
    "                                options={'strings_to_urls': False})  # 'strings_to_numbers': True\n",
    "\n",
    "    logger.info('Saving to %s' % file_name)\n",
    "\n",
    "    for key, val in export_config['sheets'].items():\n",
    "\n",
    "        # Convert the dataframe to an XlsxWriter Excel object.\n",
    "        sheet_name = key\n",
    "\n",
    "        logger.debug('The sheet name: %s' % key)\n",
    "\n",
    "        dft = val['data']\n",
    "\n",
    "        rename_map = {'year':           'Год', \n",
    "                      'main_okved':     'ОКВЭД', \n",
    "                      'main_okved_label': 'Расщифровка ОКВЭД', \n",
    "                      'company_name':   'Имя организации',\n",
    "                      'actual_address': 'Адрес организации (факт.)',\n",
    "                      'count_all':      'Кол-во всех записей',\n",
    "                      'count_values':   'Кол-во заполненных',\n",
    "                      'count_nulls':    'Кол-во пустых записей',\n",
    "                      'guests': 'Посетителей',\n",
    "                      'min':    'Минимум',\n",
    "                      'q01':    '0.01-квантиль',\n",
    "                      'q05':    '0.05-квантиль',\n",
    "                      'q10':    '0.10-квантиль',\n",
    "                      'median': 'медиана',\n",
    "                      'mean':   'арифм. среднее',\n",
    "                      'q90':    '0.90-квантиль',\n",
    "                      'q95':    '0.95-квантиль',\n",
    "                      'q99':    '0.99-квантиль',\n",
    "                      'max':    'Максимум',\n",
    "                      'plot':   'plot'}\n",
    "\n",
    "        # enrich the renaming map with the missing values\n",
    "        missing_col_names = {col_name: col_name for col_name in dft.columns.difference(rename_map)}\n",
    "        if len(missing_col_names) > 0:\n",
    "            logger.debug('Expanding the renaming map with %s' % missing_col_names)\n",
    "            rename_map.update(missing_col_names)\n",
    "\n",
    "        dft.columns = dft.columns.map(rename_map)\n",
    "\n",
    "        dft.loc[:, dft.columns != 'plot'].to_excel(xls_writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "        # Set the column width and format.\n",
    "        workbook  = xls_writer.book\n",
    "        worksheet = xls_writer.sheets[sheet_name]\n",
    "        sheet_data_range = (string.ascii_uppercase[0] + '1', \n",
    "                            string.ascii_uppercase[val['data'].shape[1]] + str(val['data'].shape[0] + 1))\n",
    "        worksheet.set_column('A:Z', width=15,  cell_format=workbook.add_format().set_align('left'))\n",
    "\n",
    "        # https://github.com/jmcnamara/XlsxWriter/issues/111\n",
    "        if 'Оц. ' in key:\n",
    "            cell_format1 = workbook.add_format()\n",
    "            cell_format1.set_num_format('0.00')\n",
    "            cell_format1.set_align('left')\n",
    "            worksheet.set_column('A:Z', width=10, cell_format=cell_format1)\n",
    "            worksheet.set_column('B:E', width=10, cell_format=workbook.add_format({'num_format': '0'}))\n",
    "            # rotation of labels\n",
    "            worksheet.set_column('C1:Q1', cell_format=workbook.add_format().set_rotation(90))\n",
    "\n",
    "        #worksheet.set_column('B:F', width = 10,  cell_format = workbook.add_format().set_align('center'))\n",
    "        #worksheet.set_column('G:G', width = 100, cell_format = workbook.add_format().set_align('left'))\n",
    "\n",
    "        # if there is the 'plot' column, insert its values to the left of table\n",
    "        if 'plot' in set(dft.columns):\n",
    "            row = 2\n",
    "            for i, v in dft.iterrows():\n",
    "                cell_addr = 'Q%d' % row\n",
    "                # logger.debug('Inserting image into %s' % cell_addr)\n",
    "                worksheet.insert_image(cell_addr, 'rugplot_%s_%d.png' % (v['ОКВЭД'], v['Год']),\n",
    "                                       {'image_data': io.BytesIO(v['plot'])})\n",
    "                row += 1\n",
    "\n",
    "        # Set the autofilter.\n",
    "        worksheet.autofilter('%s:%s' % sheet_data_range)\n",
    "        worksheet.freeze_panes(1, 2)\n",
    "\n",
    "    xls_writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_bld.groupby('year').agg({'employees': ['mean', 'median']})\n",
    "dft.columns = pd.Index(['mean', 'median'])\n",
    "dft.plot(kind='bar', ax=ax, alpha=0.9)\n",
    "\n",
    "ax.legend(loc = 'lower right', frameon=True)\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Сотрудников, чел.')\n",
    "elif LANG == 'en':     \n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Employees')\n",
    "    \n",
    "ax.tick_params(axis='x', labelrotation=0)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_emp.png', dpi=300)\n",
    "fig.savefig('images/bld_emp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "#dft = df_bld.query('heated_area <= 100000')\n",
    "dft = df_bld[['year', 'employees']].query('employees > 0')\n",
    "dft['employees_log10'] = np.log10(dft['employees'])\n",
    "\n",
    "#sns.catplot(x='year', y='heated_area_log10', data=dft, kind='violin') #, width=0.6)\n",
    "sns.boxplot(x='year', y='employees_log10', data=dft, width=0.6, color='#33CC66')\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Сотрудников, чел.')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('$log_{10}{employees}$')\n",
    "    \n",
    "#plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "ax.set_yticks(range(4))\n",
    "#ax.set_yticklabels([str(n) for n in range(4)])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_emp_boxplot.png', dpi=300)\n",
    "fig.savefig('images/bld_emp_boxplot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_bld.groupby('year').agg({'guests': ['mean', 'median']})\n",
    "dft.columns = pd.Index(['mean', 'median'])\n",
    "dft.plot(kind='bar', ax=ax, alpha=0.9)\n",
    "\n",
    "ax.legend(loc = 'lower right', frameon=True)\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Посетителей, чел.')\n",
    "elif LANG == 'en':     \n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Visitors')\n",
    "    \n",
    "ax.tick_params(axis='x', labelrotation=0)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_guests.png', dpi=300)\n",
    "fig.savefig('images/bld_guests.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "#dft = df_bld.query('heated_area <= 100000')\n",
    "dft = df_bld[['year', 'guests']].query('guests > 0')\n",
    "dft['guests_log10'] = np.log10(dft['guests'])\n",
    "\n",
    "#sns.catplot(x='year', y='heated_area_log10', data=dft, kind='violin') #, width=0.6)\n",
    "sns.boxplot(x='year', y='guests_log10', data=dft, width=0.6, color='#33CC66')\n",
    "\n",
    "if LANG =='ru':\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel('Посетителей, чел.')\n",
    "elif LANG == 'en':\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('$log_{10}{visitors}$')\n",
    "    \n",
    "ax.set_yticks(range(8))\n",
    "#ax.set_yticklabels([str(n) for n in range(4)])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_guests_boxplot.png', dpi=300)\n",
    "fig.savefig('images/bld_guests_boxplot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Attributes Over Years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distr(fig, axs, data, field_list, quantile_thr = 1, title=None, median=False):\n",
    "\n",
    "    for i, f in enumerate(field_list):\n",
    "        x = data[~data[f].isnull() & (data[f] > 0) & (data[f] < data[f].quantile(quantile_thr))][f]\n",
    "        ax = axs[0][i]\n",
    "        p = sns.distplot(x, ax=ax)\n",
    "        if median:\n",
    "            ax.axvline(x.median(), color='r')\n",
    "        # ax.annotate('median=%.2f' % x.median(), (0, 0.9))\n",
    "        p = sns.boxplot(x, ax=axs[1][i])\n",
    "\n",
    "    t = fig.suptitle(title, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distr_over_years(fig, ax, df, ylabel='Потребление ресурсов'):\n",
    "\n",
    "    '''\n",
    "    df is expected to be some value with the year in the index\n",
    "    '''\n",
    "    dft = df\n",
    "\n",
    "    dft.plot(kind='bar', ax=ax)\n",
    "    ax.set_xlabel('Год')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Consumption Over Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ee['electric_unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_ee.merge(df_bld, left_on='id_declr_building', right_index=True)[['year', 'electric_consumption']]\n",
    "dft = dft.groupby('year')['electric_consumption'].sum()/1000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Год')\n",
    "ax.set_ylabel('Электропотребление, млн. кВт*ч')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/ee_years.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_ee.merge(df_bld, left_on='id_declr_building', right_index=True)[['year', 'electric_payment']]\n",
    "dft = dft.groupby('year')['electric_payment'].sum()/1000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Год')\n",
    "ax.set_ylabel('Электропотребление, млн. руб')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/ee_payment_years.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cw['cold_water_unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_cw.merge(df_bld, left_on='id_declr_building', right_index=True)[['year', 'cold_water_consumption']]\n",
    "dft = dft.groupby('year')['cold_water_consumption'].sum()/1000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Год')\n",
    "ax.set_ylabel('Холодной воды, млн. куб. м')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/cw_years.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_cw.merge(df_bld, left_on='id_declr_building', right_index=True)[['year', 'cold_water_payment']]\n",
    "dft = dft.groupby('year')['cold_water_payment'].sum()/1000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Год')\n",
    "ax.set_ylabel('Холодной воды, млн. руб.')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/cw_payment_years.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hw['hot_water_unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_hw.merge(df_bld, left_on='id_declr_building', right_index=True)[['year', 'hot_water_consumption']]\n",
    "dft = dft.groupby('year')['hot_water_consumption'].sum()/1000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Год')\n",
    "ax.set_ylabel('Горячей воды, млн. куб. м')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/hw_years.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_hw.merge(df_bld, left_on='id_declr_building', right_index=True)[['year', 'hot_water_payment']]\n",
    "dft = dft.groupby('year')['hot_water_payment'].sum()/1000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Год')\n",
    "ax.set_ylabel('Горячей воды, млн. руб.')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/hw_payment_years.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Consumption Over Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "dft = df_bld[['year', 'heat_consumption']].groupby('year')['heat_consumption'].sum()/1000000\n",
    "\n",
    "dft.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Год')\n",
    "ax.set_ylabel('Потребление тепла, млн. Гкал')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.ticklabel_format(style='plain')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/heat_years.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Certain Parameters (Over Years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guests for 80.21 \"Основное общее и среднее (полное) общее образование\"\n",
    "\n",
    "def q05(x):\n",
    "    return(np.quantile(x, .05))\n",
    "\n",
    "def q95(x):\n",
    "    return(np.quantile(x, .95))\n",
    "\n",
    "df_declr[df_declr['main_okved'].fillna('').str.startswith('80.10.2')][['year', 'guests']]\\\n",
    "    .pivot_table(columns='year', aggfunc={'count', min, q05, np.median, np.mean, max, q95}).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_name in ['guests', 'employees', 'building_amount', 'id_org',\n",
    "                   'total_consumption_tut',\n",
    "                   'electric_per_floor_area', 'electric_per_useful_area', 'electric_per_employees_and_guests',\n",
    "                   'cold_water_per_useful_area', 'cold_water_per_employees_and_guests',\n",
    "                   'hot_water_per_employees_and_guests',\n",
    "                   'heat_per_heated_area', 'heat_per_employees_and_guests']:\n",
    "                   #'gas_per_heated_area', 'gas_per_employees_and_guests'\n",
    "                   #'tut_per_heated_area', 'tut_per_floor_area', 'tut_per_employees_and_guests']:\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(16,6), gridspec_kw = {'height_ratios':[7, 1]})\n",
    "\n",
    "    for i, y in enumerate([2014, 2015, 2016, 2017]):\n",
    "\n",
    "        data = df_declr.query('year == %d' % y)\n",
    "\n",
    "        for j, f in enumerate([param_name]):\n",
    "            \n",
    "            if f in {'id_org'}:\n",
    "                quantile_thr_lo = 0\n",
    "                quantile_thr_hi = 1\n",
    "            else:\n",
    "                quantile_thr_lo = 0.05\n",
    "                quantile_thr_hi = 0.95\n",
    "                \n",
    "            x = data[~data[f].isnull() & \n",
    "                     (data[f] > 0) & \n",
    "                     (data[f] >= data[f].quantile(quantile_thr_lo)) &\n",
    "                     (data[f] <= data[f].quantile(quantile_thr_hi))][f]\n",
    "            \n",
    "            # distribution plot\n",
    "            ax_dp = axs[j][i]\n",
    "            p = sns.distplot(x, ax=ax_dp)\n",
    "            ax_dp.set_title('Случаев: {}'.format(len(x)))\n",
    "            ax_dp.set_xlabel('')\n",
    "            if True:\n",
    "                ax_dp.axvline(x.median(), color='r')\n",
    "                ax_dp.annotate('median=%.2f' % x.median(), (0.5, 0.9), xycoords='axes fraction')\n",
    "                \n",
    "            # box plot\n",
    "            ax_bp = axs[j+1][i]            \n",
    "            p = sns.boxplot(x, ax=ax_bp)\n",
    "            ax_bp.set_xlabel('')\n",
    "            ax_bp.set_xlim(ax_dp.get_xlim())\n",
    "\n",
    "            #t = ax.set_title('%d' % y)\n",
    "\n",
    "    t = fig.suptitle('{} по годам ({:.2f}-{:.2f}-квантили)'.format(param_name, quantile_thr_lo, quantile_thr_hi), size=15)\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    fig.savefig('images/{}.png'.format(param_name), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total_consumption_tut - testing whether they are different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "year_list = (2014, 2015, 2016, 2017)\n",
    "\n",
    "var_name = 'total_consumption_tut'\n",
    "print(var_name)\n",
    "for y1 in year_list:\n",
    "    for y2 in year_list:\n",
    "        if y1 < y2:\n",
    "            print('%d vs %d: ' % (y1, y2), end='')\n",
    "            print(ks_2samp(df_declr.query('year == %d' % y1)[var_name], df_declr.query('year == %d' % y2)[var_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 2017 year is different from the previous years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Efficiency Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld.groupby('dd_okved')['dd_okved'].count().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 7))\n",
    "\n",
    "plt.subplots_adjust(wspace=1)\n",
    "\n",
    "year=2017\n",
    "dd_okved='85.13'\n",
    "#main_okved='all'\n",
    "\n",
    "if main_okved == 'all':\n",
    "    dft = df_bld_tmp.query('year==@year')\n",
    "else:\n",
    "    dft = df_bld_tmp\\\n",
    "        .merge(df_bld['dd_okved'], left_on='id', right_index=True, how='left')\\\n",
    "        .query('year==@year and dd_okved==@dd_okved')\n",
    "\n",
    "dft['electric_per_floor_area_log']           = np.log10(dft['electric_per_floor_area'])\n",
    "dft['electric_per_employees_and_guests_log'] = np.log10(dft['electric_per_employees_and_guests'])\n",
    "   \n",
    "ax = axs[0]\n",
    "p = sns.scatterplot(data=dft, \n",
    "                    x='electric_points', \n",
    "                    y='electric_per_floor_area_log', \n",
    "                    hue='efficiency_class_name', palette='RdYlGn_r', hue_order=['A','B','C','D','E','F','G'],\n",
    "                    linewidth=0, alpha=0.8, ax=ax)\n",
    "\n",
    "if LANG == 'en':    \n",
    "    ax.set_xlabel('electric points')\n",
    "    ax.set_ylabel('electric consumption per floor area, $log_{10}$ scale')\n",
    "\n",
    "ax = axs[1]\n",
    "p = sns.scatterplot(data=dft, \n",
    "                    x='electric_points', \n",
    "                    y='electric_per_employees_and_guests_log', \n",
    "                    hue='efficiency_class_name', palette='RdYlGn_r', hue_order=['A','B','C','D','E','F','G'],\n",
    "                    linewidth=0, alpha=0.8, ax=ax)\n",
    "\n",
    "if LANG == 'en':    \n",
    "    ax.set_xlabel('electric points')\n",
    "    ax.set_ylabel('electric consumption per persons, $log_{10}$ scale')\n",
    "\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "# suptitle = 'Распределение класса энергоэффективности здания в зависимости от\\n'\\\n",
    "#            'баллов (по электроэнергии) и удельных показателей\\n'\\\n",
    "#            '(данные за {} год) для'.format(year)\n",
    "\n",
    "# if main_okved == 'all':\n",
    "#     suptitle = suptitle + ' всех зданий'\n",
    "# else:\n",
    "#     suptitle = suptitle + ' зданий с основным ОКВЭД {}'.format(main_okved)\n",
    "\n",
    "# fig.suptitle(suptitle)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "fig.savefig(f'images/ec_ee_efficiency_class_{year}_{dd_okved}.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 7))\n",
    "\n",
    "plt.subplots_adjust(wspace=1)\n",
    "\n",
    "year=2017\n",
    "dd_okved='85.13'\n",
    "#main_okved='all'\n",
    "\n",
    "if main_okved == 'all':\n",
    "    dft = df_bld_tmp.query('year==@year')\n",
    "else:\n",
    "    dft = df_bld_tmp\\\n",
    "        .merge(df_bld['dd_okved'], left_on='id', right_index=True, how='left')\\\n",
    "        .query('year==@year and dd_okved==@dd_okved')\n",
    "\n",
    "dft['heat_per_heated_area_log']           = np.log10(dft['heat_per_heated_area'])\n",
    "dft['heat_per_employees_and_guests_log']  = np.log10(dft['heat_per_employees_and_guests'])\n",
    "   \n",
    "ax = axs[0]\n",
    "p = sns.scatterplot(data=dft, \n",
    "                    x='heat_points', \n",
    "                    y='heat_per_heated_area_log', \n",
    "                    hue='efficiency_class_name', palette='RdYlGn_r', hue_order=['A','B','C','D','E','F','G'],\n",
    "                    linewidth=0, alpha=0.8, ax=ax)\n",
    "\n",
    "if LANG == 'en':    \n",
    "    ax.set_xlabel('heat points')\n",
    "    ax.set_ylabel('heat consumption per heated area, $log_{10}$ scale')\n",
    "\n",
    "ax = axs[1]\n",
    "p = sns.scatterplot(data=dft, \n",
    "                    x='heat_points', \n",
    "                    y='heat_per_employees_and_guests_log', \n",
    "                    hue='efficiency_class_name', palette='RdYlGn_r', hue_order=['A','B','C','D','E','F','G'],\n",
    "                    linewidth=0, alpha=0.8, ax=ax)\n",
    "\n",
    "if LANG == 'en':    \n",
    "    ax.set_xlabel('heat points')\n",
    "    ax.set_ylabel('heat consumption per persons, $log_{10}$ scale')\n",
    "\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "# suptitle = 'Распределение класса энергоэффективности здания в зависимости от\\n'\\\n",
    "#            'баллов (по электроэнергии) и удельных показателей\\n'\\\n",
    "#            '(данные за {} год) для'.format(year)\n",
    "\n",
    "# if main_okved == 'all':\n",
    "#     suptitle = suptitle + ' всех зданий'\n",
    "# else:\n",
    "#     suptitle = suptitle + ' зданий с основным ОКВЭД {}'.format(main_okved)\n",
    "\n",
    "# fig.suptitle(suptitle)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "fig.savefig(f'images/ec_ht_efficiency_class_{year}_{dd_okved}.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks for 'Fraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisq_stat(O, E):\n",
    "    return(sum( [(o - e)**2/e for (o, e) in zip(O, E)] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_bld['employees'].dropna().astype('str').str.slice(0, 1).astype('int').rename('observed')\n",
    "benford_observed = dft[dft != 0].value_counts().sort_index()\n",
    "\n",
    "benford_expected = pd.Series([len(dft)*np.log10(1 + 1./i) for i in range(1, 10)], index=range(1, 10), name='expected')\n",
    "benford = pd.concat([benford_observed, benford_expected], axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))\n",
    "ax = axs\n",
    "benford.plot(kind='bar', ax=ax)\n",
    "ax.legend(['observed', 'expected'])\n",
    "\n",
    "ax.set_xlabel('First digit')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/bld_employees_benford.png', dpi=300)\n",
    "fig.savefig('images/bld_employees_benford.pdf')\n",
    "\n",
    "print(chisq_stat(benford['observed'].to_numpy(), benford['expected'].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_bld['guests'].dropna().astype('str').str.slice(0, 1).astype('int').rename('observed')\n",
    "benford_observed = dft[dft != 0].value_counts().sort_index()\n",
    "\n",
    "benford_expected = pd.Series([len(dft)*np.log10(1 + 1./i) for i in range(1, 10)], index=range(1, 10), name='expected')\n",
    "benford = pd.concat([benford_observed, benford_expected], axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))\n",
    "ax = axs\n",
    "benford.plot(kind='bar', ax=ax)\n",
    "ax.legend(['observed', 'expected'])\n",
    "\n",
    "ax.set_xlabel('First digit')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('images/bld_guests_benford.png', dpi=300)\n",
    "fig.savefig('images/bld_guests_benford.pdf')\n",
    "\n",
    "print(chisq_stat(benford['observed'].to_numpy(), benford['expected'].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_bld['heat_consumption'].dropna().astype('str').str.slice(0, 1).astype('int').rename('observed')\n",
    "benford_observed = dft[dft != 0].value_counts().sort_index()\n",
    "\n",
    "benford_expected = pd.Series([len(dft)*np.log10(1 + 1./i) for i in range(1, 10)], index=range(1, 10), name='expected')\n",
    "benford = pd.concat([benford_observed, benford_expected], axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))\n",
    "ax = axs\n",
    "benford.plot(kind='bar', ax=ax)\n",
    "ax.legend(['observed', 'expected'])\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('images/bld_ht_consumption_benford.png', dpi=300)\n",
    "fig.savefig('images/bld_ht_consumption_benford.pdf')\n",
    "\n",
    "print(chisq_stat(benford['observed'].to_numpy(), benford['expected'].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Data Input Validation\n",
    "\n",
    "1. Есть пропущенные данные.\n",
    "2. Некоторые организации указывали разные ОКВЭД для разных годов.\n",
    "3. Количество сотрудников иногда задано некорректно?\n",
    "4. Количество гостей задаётся оценочно.\n",
    "5. Есть здания, по которым нулевое потребление электроэнергии."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "512px",
    "left": "493px",
    "top": "516.571px",
    "width": "288.509px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
